{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 1**"
      ],
      "metadata": {
        "id": "gS3hAQ2qHTyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mN1AXqNBYSy",
        "outputId": "bfc6e902-17e8-43b7-ab76-76de09311e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import io \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "import pickle "
      ],
      "metadata": {
        "id": "B40N9hLQBvux"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_id = 2204923 "
      ],
      "metadata": {
        "id": "42BMCo5zB4gN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#numpy seed\n",
        "np.random.seed(student_id)"
      ],
      "metadata": {
        "id": "rkHxDkChB_Qy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, i want to run 4 different classifier for OLID dataset for my text classiffication. I will use Support vector machine classifier, Decision Tree classifier, Convolution Neural Network and Long short term memory(a type of recurrent neural network)"
      ],
      "metadata": {
        "id": "a46AHnrLYAWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AApQ1ffQ04h1",
        "outputId": "a68a099f-fd6f-4523-ed1c-02a2caf48cc9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proportion for each label in the train dataset"
      ],
      "metadata": {
        "id": "o7JG7lfuWA5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read the dataset\n",
        "traindf = pd.read_csv(\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv\", index_col=0)\n",
        "\n",
        "# count the number of offensive and non-offensive examples\n",
        "train_offensive_count = (traindf[\"label\"] == \"OFF\").sum()\n",
        "train_non_offensive_count = (traindf[\"label\"] == \"NOT\").sum()\n",
        "\n",
        "# calculate the proportions\n",
        "total_count = len(traindf)\n",
        "train_offensive_proportion = (train_offensive_count / total_count)*100\n",
        "train_non_offensive_proportion = (train_non_offensive_count / total_count)*100\n",
        "\n",
        "print(traindf.head())\n",
        "print(\"\")\n",
        "print(\"shape of validation dataset:\")\n",
        "print(traindf.shape)\n",
        "print(\"\")\n",
        "print(\"proportion of each label\")\n",
        "print(f\"Proportion of offensive speech: {train_offensive_proportion:.2f}\")\n",
        "print(f\"Proportion of non-offensive speech: {train_non_offensive_proportion:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOCBV2aZSn3C",
        "outputId": "65ea4b8c-d8c3-410c-fe30-1c9af277fafd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   tweet label\n",
            "id                                                            \n",
            "42884  @USER I’m done with you as well. An INTENTIONA...   NOT\n",
            "92152  I now have over 6k followers.  Only 94k to go ...   NOT\n",
            "65475  @USER Tom was bought! He is more interested in...   NOT\n",
            "22144  @USER @USER Even her brother thinks she is a m...   OFF\n",
            "81048  @USER @USER @USER @USER @USER I can understand...   OFF\n",
            "\n",
            "shape of validation dataset:\n",
            "(12313, 2)\n",
            "\n",
            "proportion of each label\n",
            "Proportion of offensive speech: 33.23\n",
            "Proportion of non-offensive speech: 66.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "proportion for labels in the validation dataset"
      ],
      "metadata": {
        "id": "vXx9_RwYWNcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read the dataset\n",
        "validdf = pd.read_csv(\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/valid.csv\", index_col=0)\n",
        "\n",
        "# count the number of offensive and non-offensive examples\n",
        "valid_offensive_count = (validdf[\"label\"] == \"OFF\").sum()\n",
        "valid_non_offensive_count = (validdf[\"label\"] == \"NOT\").sum()\n",
        "\n",
        "# calculate the proportions\n",
        "total_count = len(validdf)\n",
        "valid_offensive_proportion = (valid_offensive_count / total_count)*100\n",
        "valid_non_offensive_proportion = (valid_non_offensive_count / total_count)*100\n",
        "\n",
        "print(validdf.head())\n",
        "print(\"\")\n",
        "print(\"shape of validation dataset:\")\n",
        "print(validdf.shape)\n",
        "print(\"\")\n",
        "print(\"proportion of each label\")\n",
        "print(f\"Proportion of offensive speech: {valid_offensive_proportion:.2f}\")\n",
        "print(f\"Proportion of non-offensive speech: {valid_non_offensive_proportion:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-vDnWD6WUkZ",
        "outputId": "f41271d8-98a5-417b-fd09-9307ac16e8c6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   tweet label\n",
            "id                                                            \n",
            "12476  @USER @USER @USER Trump is declassifying infor...   NOT\n",
            "23242  @USER Ha even with them trying to rig the syst...   NOT\n",
            "97885  @USER @USER @USER Man you really thought this ...   NOT\n",
            "43414  @USER Ms. Clinton - you are a class act. My re...   OFF\n",
            "81403  @USER It’s still here at 753. If someone did t...   NOT\n",
            "\n",
            "shape of validation dataset:\n",
            "(927, 2)\n",
            "\n",
            "proportion of each label\n",
            "Proportion of offensive speech: 33.23\n",
            "Proportion of non-offensive speech: 66.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the proportion and shape of test dataset."
      ],
      "metadata": {
        "id": "DSiOtR_qYBbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read the dataset\n",
        "testdf = pd.read_csv(\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv\", index_col=0)\n",
        "\n",
        "# count the number of offensive and non-offensive examples\n",
        "test_offensive_count = (testdf[\"label\"] == \"OFF\").sum()\n",
        "test_non_offensive_count = (testdf[\"label\"] == \"NOT\").sum()\n",
        "\n",
        "# calculate the proportions\n",
        "total_count = len(testdf)\n",
        "test_offensive_proportion = (test_offensive_count / total_count)*100\n",
        "test_non_offensive_proportion = (test_non_offensive_count / total_count)*100\n",
        "\n",
        "print(testdf.head())\n",
        "print(\"\")\n",
        "print(\"shape of validation dataset:\")\n",
        "print(testdf.shape)\n",
        "print(\"\")\n",
        "print(\"proportion of each label\")\n",
        "print(f\"Proportion of offensive speech: {test_offensive_proportion:.2f}\")\n",
        "print(f\"Proportion of non-offensive speech: {test_non_offensive_proportion:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZDjQfpCYNfK",
        "outputId": "58d3bebd-f4d9-429c-df1d-47e6a12fba6a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   tweet label\n",
            "id                                                            \n",
            "15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   OFF\n",
            "27014  #ConstitutionDay is revered by Conservatives, ...   NOT\n",
            "30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...   NOT\n",
            "13876  #Watching #Boomer getting the news that she is...   NOT\n",
            "60133  #NoPasaran: Unity demo to oppose the far-right...   OFF\n",
            "\n",
            "shape of validation dataset:\n",
            "(860, 2)\n",
            "\n",
            "proportion of each label\n",
            "Proportion of offensive speech: 27.91\n",
            "Proportion of non-offensive speech: 72.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the accuracy performance of the Support vector machine classiffier"
      ],
      "metadata": {
        "id": "b9mYzubzaq-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "import joblib\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "\n",
        "# Define the function for loading the data\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    X = data['tweet'].values\n",
        "    y = data['label'].values\n",
        "    return X, y\n",
        "\n",
        "# Define the function for extracting handcrafted features from the text\n",
        "def extract_handcrafted_features(texts):\n",
        "    features = []\n",
        "    for text in texts:\n",
        "        # Extract handcrafted features such as character n-grams, punctuation marks, capitalization, etc.\n",
        "        # Append the features to the list\n",
        "        features.append([len(text), len(text.split()), len(text.splitlines())])\n",
        "    return np.array(features)\n",
        "\n",
        "# Load the data and split it into training and testing sets\n",
        "X_train, y_train = load_data('/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv')\n",
        "X_test, y_test = load_data('/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv')\n",
        "\n",
        "# Represent the text using word n-grams and stop words of English\n",
        "vectorizer = CountVectorizer(ngram_range=(1,3), stop_words='english')\n",
        "X_train_ngrams = vectorizer.fit_transform(X_train)\n",
        "X_test_ngrams = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the SVM model with word n-grams and linear kernel\n",
        "svm = SVC(C=1, gamma=0.01, kernel='linear')\n",
        "svm.fit(X_train_ngrams, y_train)\n",
        "\n",
        "# Evaluate the SVM model on the test set with word n-grams\n",
        "y_pred_svm_ngrams = svm.predict(X_test_ngrams)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_svm_ngrams = accuracy_score(y_test, y_pred_svm_ngrams)\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(svm, '/content/gdrive/MyDrive/CE807/Assignment2/2204923/svm_model.pkl')\n",
        "\n",
        "# Compute the evaluation metrics\n",
        "print(\"SVM with word n-grams and stop words of English:\")\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "print(\"Macro F1 score:\", f1_score(y_test, y_pred_svm_ngrams, average='macro'))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_svm_ngrams))\n",
        "print(\"Accuracy of SVM with word n-grams and stop words of English:\", accuracy_svm_ngrams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhnj4377DHyx",
        "outputId": "73912f05-b5ce-4dea-ac2d-c9477cbbb097"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM with word n-grams and stop words of English:\n",
            "F1 score: 0.5672371638141809\n",
            "Precision: 0.6863905325443787\n",
            "Recall: 0.48333333333333334\n",
            "Macro F1 score: 0.7161128610832919\n",
            "Confusion matrix:\n",
            " [[567  53]\n",
            " [124 116]]\n",
            "Accuracy of SVM with word n-grams and stop words of English: 0.7941860465116279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements a binary text classification task using Support Vector Machines (SVM) algorithm and evaluates their performance using various evaluation metrics such as F1 score, precision, recall, and confusion matrix. The input data is loaded from CSV files, and then pre-processed using CountVectorizer which convert collection of text documents to a vector, to represent the text as word n-grams. Ngram are use in analysing text with sequence of words.  i define a function, Handcrafted features such as character n-grams, punctuation marks (stop word is set to english language), and capitalization are also extracted from the text. The SVM model is trained on the n-gram features. The trained models are then used to predict the labels of the test set which gives approximately 0.8  accuracy( we can also represent in percentage by multiplying it by 100.which give 80%) but i prefer representing it statistically."
      ],
      "metadata": {
        "id": "LLUaO9Iaclm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using decision Tree as text classifier**"
      ],
      "metadata": {
        "id": "QEOa69xGi9Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# Define the function for loading the data\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv')\n",
        "    X = data['tweet'].values\n",
        "    y = data['label'].values\n",
        "    return X, y\n",
        "\n",
        "# Load the data and split it into training and testing sets\n",
        "X_train, y_train = load_data('/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv')\n",
        "X_test, y_dtc_test = load_data('/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv')\n",
        "\n",
        "# Represent the text using word n-grams\n",
        "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
        "X_train_ngrams = vectorizer.fit_transform(X_train)\n",
        "X_test_ngrams = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Decision Tree Classifier with word n-grams\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train_ngrams, y_train)\n",
        "\n",
        "# Predict on the test set with word n-grams\n",
        "y_pred_dtc_ngrams = dtc.predict(X_test_ngrams)\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(dtc, '/content/gdrive/MyDrive/CE807/Assignment2/2204923/dtc_model.pkl')\n",
        "\n",
        "# Evaluate the Decision Tree Classifier on the test set with word n-grams\n",
        "accuracy_dtc_ngrams = accuracy_score(y_dtc_test, y_pred_dtc_ngrams)\n",
        "f1_dtc_ngrams = f1_score(y_dtc_test, y_pred_dtc_ngrams, average='macro')\n",
        "precision_dtc_ngrams = precision_score(y_dtc_test, y_pred_dtc_ngrams, average='macro')\n",
        "recall_dtc_ngrams = recall_score(y_dtc_test, y_pred_dtc_ngrams, average='macro')\n",
        "confusion_matrix_dtc_ngrams = confusion_matrix(y_dtc_test, y_pred_dtc_ngrams, labels=['NOT', 'OFF'])\n",
        "print(\" \")\n",
        "# Print the metrics of the Decision Tree Classifier with word n-grams\n",
        "print(\"Accuracy of Decision Tree Classifier with word n-grams:\", accuracy_dtc_ngrams)\n",
        "print(\"F1 score of Decision Tree Classifier with word n-grams:\", f1_dtc_ngrams)\n",
        "print(\"Precision of Decision Tree Classifier with word n-grams:\", precision_dtc_ngrams)\n",
        "print(\"Recall of Decision Tree Classifier with word n-grams:\", recall_dtc_ngrams)\n",
        "print(\"Confusion matrix of Decision Tree Classifier with word n-grams:\")\n",
        "print(confusion_matrix_dtc_ngrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOYOJFAr8NNF",
        "outputId": "436588b5-5ac6-431f-af12-8e496e3dd39c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Accuracy of Decision Tree Classifier with word n-grams: 0.9987817753593763\n",
            "F1 score of Decision Tree Classifier with word n-grams: 0.998626161846101\n",
            "Precision of Decision Tree Classifier with word n-grams: 0.9990893637688198\n",
            "Recall of Decision Tree Classifier with word n-grams: 0.9981671554252199\n",
            "Confusion matrix of Decision Tree Classifier with word n-grams:\n",
            "[[8221    0]\n",
            " [  15 4077]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads a dataset of tweets, preprocesses the text data by converting it to word n-grams, trains a decision tree classifier on the preprocessed data, and evaluates the classifier on a test set using various performance metrics such as accuracy, F1 score, precision, recall, and confusion matrix. The code defines a function for loading the data from a CSV file and another function for extracting the n-gram features from the text data. The accuracy of the fitted model is 0.99.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dAIltF-Ik7O_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using CNN as the fitted model**"
      ],
      "metadata": {
        "id": "ZNAwda8McnfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv')\n",
        "test_data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv')\n",
        "\n",
        "# Tokenize the text and remove stop words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['tweet'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['tweet'])\n",
        "X_train = [[word for word in seq if word not in stop_words] for seq in X_train]\n",
        "X_test = tokenizer.texts_to_sequences(test_data['tweet'])\n",
        "X_test = [[word for word in seq if word not in stop_words] for seq in X_test]\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "max_len = 100\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_len))\n",
        "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Convert labels to numerical values\n",
        "encoder = LabelEncoder()\n",
        "train_data['label'] = encoder.fit_transform(train_data['label'])\n",
        "test_data['label'] = encoder.transform(test_data['label'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, train_data['label'], epochs=10, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.round(y_pred).astype(int)\n",
        "accuracy = model.evaluate(X_test, test_data['label'], verbose=0)[1]\n",
        "f1 = f1_score(test_data['label'], y_pred)\n",
        "precision = precision_score(test_data['label'], y_pred)\n",
        "recall = recall_score(test_data['label'], y_pred)\n",
        "cm = confusion_matrix(test_data['label'], y_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Accuracy of CNN:\", accuracy)\n",
        "print(\"F1 score of CNN:\", f1)\n",
        "print(\"Precision of CNN:\", precision)\n",
        "print(\"Recall of CNN:\", recall)\n",
        "print(\"Confusion matrix of CNN:\")\n",
        "print(cm)\n",
        "\n",
        "# Save the model and prediction outcomes\n",
        "model.save('/content/gdrive/MyDrive/CE807/Assignment2/2204923/cnn_model.h5')\n",
        "np.savetxt('/content/gdrive/MyDrive/CE807/Assignment2/2204923/output_test_cnn.csv', y_pred, fmt='%d')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG06kJ_j5CA6",
        "outputId": "ce867d46-ba88-4f42-8cbf-75ff04ba32b2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "174/174 [==============================] - 23s 121ms/step - loss: 0.6256 - accuracy: 0.6675 - val_loss: 0.5866 - val_accuracy: 0.6688\n",
            "Epoch 2/10\n",
            "174/174 [==============================] - 19s 111ms/step - loss: 0.4412 - accuracy: 0.7999 - val_loss: 0.5486 - val_accuracy: 0.7411\n",
            "Epoch 3/10\n",
            "174/174 [==============================] - 19s 111ms/step - loss: 0.2400 - accuracy: 0.9143 - val_loss: 0.7188 - val_accuracy: 0.7256\n",
            "Epoch 4/10\n",
            "174/174 [==============================] - 19s 109ms/step - loss: 0.1119 - accuracy: 0.9671 - val_loss: 1.0127 - val_accuracy: 0.7078\n",
            "Epoch 5/10\n",
            "174/174 [==============================] - 21s 118ms/step - loss: 0.0611 - accuracy: 0.9840 - val_loss: 1.1739 - val_accuracy: 0.7183\n",
            "Epoch 6/10\n",
            "174/174 [==============================] - 20s 117ms/step - loss: 0.0382 - accuracy: 0.9902 - val_loss: 1.3324 - val_accuracy: 0.6981\n",
            "Epoch 7/10\n",
            "174/174 [==============================] - 19s 111ms/step - loss: 0.0302 - accuracy: 0.9944 - val_loss: 1.4524 - val_accuracy: 0.7086\n",
            "Epoch 8/10\n",
            "174/174 [==============================] - 19s 110ms/step - loss: 0.0214 - accuracy: 0.9960 - val_loss: 1.6316 - val_accuracy: 0.6948\n",
            "Epoch 9/10\n",
            "174/174 [==============================] - 19s 111ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 1.7856 - val_accuracy: 0.7045\n",
            "Epoch 10/10\n",
            "174/174 [==============================] - 21s 123ms/step - loss: 0.0179 - accuracy: 0.9977 - val_loss: 1.9136 - val_accuracy: 0.7313\n",
            "27/27 [==============================] - 0s 11ms/step\n",
            "Accuracy of CNN: 0.7767441868782043\n",
            "F1 score of CNN: 0.5675675675675677\n",
            "Precision of CNN: 0.6176470588235294\n",
            "Recall of CNN: 0.525\n",
            "Confusion matrix of CNN:\n",
            "[[542  78]\n",
            " [114 126]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i use the code above for training and evaluating a Convolutional Neural Network (CNN) model to classify tweets into two categories: either being related to hate speech or not. I use the Keras API of TensorFlow library for building the model architecture, tokenizing and padding the tweet sequences, and fitting the model to the training data. I also uses scikit-learn library for encoding the labels and computing the evaluation metrics (accuracy, F1 score, precision, recall, and confusion matrix) on the test set. Finally i  predict the labels of the test set, which gives approxmately 0.77 accuracy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xMmBEn5bnnLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Long Short Term Memory(LSTM)**"
      ],
      "metadata": {
        "id": "42ff9GESph8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv')\n",
        "test_lstm_data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv')\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['tweet'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['tweet'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['tweet'])\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "max_len = 100\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_len))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "train_data['label'] = encoder.fit_transform(train_data['label'])\n",
        "test_lstm_data['label'] = encoder.transform(test_lstm_data['label'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, train_data['label'], epochs=10, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "#loss, accuracy = model.evaluate(X_test, test_lstm_data['label'], verbose=0)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_lstm_pred = model.predict(X_test)\n",
        "y_lstm_pred = np.round(y_lstm_pred).astype(int)\n",
        "acc = model.evaluate(X_test, test_lstm_data['label'], verbose=0)[1]\n",
        "f1s = f1_score(test_lstm_data['label'], y_lstm_pred)\n",
        "precisions = precision_score(test_lstm_data['label'], y_lstm_pred)\n",
        "recalls = recall_score(test_lstm_data['label'], y_lstm_pred)\n",
        "cms = confusion_matrix(test_lstm_data['label'], y_lstm_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Accuracy of LSTM:\", acc)\n",
        "print(\"F1 score of LSTM:\", f1s)\n",
        "print(\"Precision of LSTM:\", precision)\n",
        "print(\"Recall of LSTM:\", recalls)\n",
        "print(\"Confusion matrix of LSTM:\")\n",
        "print(cms)\n",
        "# Print the accuracy\n",
        "print(\"Accuracy of LSTM:\", acc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goA4Mt-ooib7",
        "outputId": "0e1e5954-4ac4-4585-f508-ff0b5f2758e7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "174/174 [==============================] - 95s 525ms/step - loss: 0.6450 - accuracy: 0.6650 - val_loss: 0.6367 - val_accuracy: 0.6672\n",
            "Epoch 2/10\n",
            "174/174 [==============================] - 84s 485ms/step - loss: 0.6396 - accuracy: 0.6677 - val_loss: 0.6390 - val_accuracy: 0.6672\n",
            "Epoch 3/10\n",
            "174/174 [==============================] - 85s 491ms/step - loss: 0.6385 - accuracy: 0.6677 - val_loss: 0.6369 - val_accuracy: 0.6672\n",
            "Epoch 4/10\n",
            "174/174 [==============================] - 90s 516ms/step - loss: 0.6390 - accuracy: 0.6677 - val_loss: 0.6383 - val_accuracy: 0.6672\n",
            "Epoch 5/10\n",
            "174/174 [==============================] - 86s 497ms/step - loss: 0.6379 - accuracy: 0.6678 - val_loss: 0.6365 - val_accuracy: 0.6672\n",
            "Epoch 6/10\n",
            "174/174 [==============================] - 86s 495ms/step - loss: 0.6389 - accuracy: 0.6678 - val_loss: 0.6360 - val_accuracy: 0.6672\n",
            "Epoch 7/10\n",
            "174/174 [==============================] - 88s 502ms/step - loss: 0.6377 - accuracy: 0.6678 - val_loss: 0.6362 - val_accuracy: 0.6672\n",
            "Epoch 8/10\n",
            "174/174 [==============================] - 85s 488ms/step - loss: 0.6370 - accuracy: 0.6679 - val_loss: 0.6361 - val_accuracy: 0.6672\n",
            "Epoch 9/10\n",
            "174/174 [==============================] - 84s 486ms/step - loss: 0.6390 - accuracy: 0.6679 - val_loss: 0.6360 - val_accuracy: 0.6672\n",
            "Epoch 10/10\n",
            "174/174 [==============================] - 86s 496ms/step - loss: 0.6370 - accuracy: 0.6679 - val_loss: 0.6360 - val_accuracy: 0.6672\n",
            "27/27 [==============================] - 1s 40ms/step\n",
            "Accuracy of LSTM: 0.7209302186965942\n",
            "F1 score of LSTM: 0.0\n",
            "Precision of LSTM: 0.6176470588235294\n",
            "Recall of LSTM: 0.0\n",
            "Confusion matrix of LSTM:\n",
            "[[620   0]\n",
            " [240   0]]\n",
            "Accuracy of LSTM: 0.7209302186965942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above implements a LSTM (Long Short-Term Memory) neural network model for text classification on tweets. The model is built using the Keras API of TensorFlow just as the CNN. I  first loads the training and test data from CSV files and tokenizes the text using the Tokenizer class. The sequences are then padded to have the same length.\n",
        "\n",
        "The LSTM model is defined with an Embedding layer, an LSTM layer with 128 units, a Dense layer with 64 units and a Dropout layer with a dropout rate of 0.5. The model is compiled with binary cross-entropy loss which compare each of the predicted probability to actual class output, 0 or 1 and the Adam optimizer to adjust the learning rate for each parameter.\n",
        "\n",
        "The training data labels are encoded using the LabelEncoder class from scikit-learn. The model is then trained on the training data using 10 epochs and a batch size of 64 with a 10% validation split. The model is evaluated on the test data and metrics such as accuracy is printed which gives 0.72 accuracy."
      ],
      "metadata": {
        "id": "oLqy1Tr8rKv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting all the model performance at a glance by building a function for easier explanation. we will get the prediction output of each of the model computed above to include in the function"
      ],
      "metadata": {
        "id": "KAaa0PMCvsxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "def compute_performance(y_true, y_pred, split='test'):\n",
        "    print('Computing different performance metrics on', split, 'set of Dataset')\n",
        "    \n",
        "    # Compute and print accuracy\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "    \n",
        "    # Compute and print recall, precision, f1-score (macro), and confusion matrix\n",
        "    labels = np.unique(y_true)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    recall = np.diag(cm) / np.sum(cm, axis=1)\n",
        "    precision = np.diag(cm) / np.sum(cm, axis=0)\n",
        "    f1 = 2 * precision * recall / (precision + recall)\n",
        "    f1_macro = np.mean(f1)\n",
        "    \n",
        "    print('Confusion matrix:')\n",
        "    print(cm)\n",
        "    print('Recall (macro):', np.mean(recall))\n",
        "    print('Precision (macro):', np.mean(precision))\n",
        "    print('F1 score (macro):', f1_macro)\n",
        "    print('')\n",
        "    \n",
        "print('performance metric for support vector machine:')\n",
        "compute_performance(y_test, y_pred_svm_ngrams, split='test')\n",
        "print('performance metric for Decision Tree Classifier:')\n",
        "compute_performance(y_dtc_test, y_pred_dtc_ngrams, split='test') \n",
        "print('performance metric for LSTM:')\n",
        "compute_performance(test_lstm_data['label'], y_lstm_pred, split='test') \n",
        "print('performance metric for CNN:') \n",
        "compute_performance(test_data['label'], y_pred, split='test') \n",
        "\n",
        "\n",
        "   \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njIYgs3hcHrc",
        "outputId": "269b0209-0467-425a-8724-497d3dc55a7a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performance metric for support vector machine:\n",
            "Computing different performance metrics on test set of Dataset\n",
            "Accuracy: 0.7941860465116279\n",
            "Confusion matrix:\n",
            "[[567  53]\n",
            " [124 116]]\n",
            "Recall (macro): 0.6989247311827957\n",
            "Precision (macro): 0.7534702300927393\n",
            "F1 score (macro): 0.7161128610832919\n",
            "\n",
            "performance metric for Decision Tree Classifier:\n",
            "Computing different performance metrics on test set of Dataset\n",
            "Accuracy: 0.9987817753593763\n",
            "Confusion matrix:\n",
            "[[8221    0]\n",
            " [  15 4077]]\n",
            "Recall (macro): 0.9981671554252199\n",
            "Precision (macro): 0.9990893637688198\n",
            "F1 score (macro): 0.998626161846101\n",
            "\n",
            "performance metric for LSTM:\n",
            "Computing different performance metrics on test set of Dataset\n",
            "Accuracy: 0.7209302325581395\n",
            "Confusion matrix:\n",
            "[[620   0]\n",
            " [240   0]]\n",
            "Recall (macro): 0.5\n",
            "Precision (macro): nan\n",
            "F1 score (macro): nan\n",
            "\n",
            "performance metric for CNN:\n",
            "Computing different performance metrics on test set of Dataset\n",
            "Accuracy: 0.7767441860465116\n",
            "Confusion matrix:\n",
            "[[542  78]\n",
            " [114 126]]\n",
            "Recall (macro): 0.6995967741935484\n",
            "Precision (macro): 0.7219332855093257\n",
            "F1 score (macro): 0.7085486740659155\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-0e049af5c42d>:14: RuntimeWarning: invalid value encountered in true_divide\n",
            "  precision = np.diag(cm) / np.sum(cm, axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the performance metrics output for diffrent model above, it clear that Decision tree gives the best accuracy performance but having a 99% accuracy doesn't mean it fit the training data perfection, it might mean there is a problem using the model. \n",
        "\n",
        "Using the LSTM model to fit the traing and test data gives 72% accuracy but precision, F1 score is not able to compute. Also, when i tried increasing the dataset by shuffling and randomly selecting the train data base on different sizes. The accuracy is still unchanges which means it does not fit the data well.\n",
        "\n",
        "Now using Support vector machine classifier, it gives a approximately 80% accuracy with f1 score of 0.72. SVM perform well in dataset that have high dimension feature space. It make text classification easier by eliminating the need for feature selection. SVM is also better in binary classification which make it suit this task  better.\n",
        "\n",
        "CNN, gives accuracy of approximately 0.77 with macro f1 score of 0.7. CNNs are particularly effective when working with text data that has a spatial structure, such as text data in the form of images, where the spatial arrangement of words within a sentence or document provides additional information that can be leveraged by the model. For example, CNNs have been shown to be effective in text classification tasks such as sentiment analysis, where the location of specific words or phrases within a sentence can be indicative of sentiment.\n",
        "\n",
        "In addition, CNNs can be beneficial when working with text data that has a large vocabulary, as they are able to learn high-level, abstract representations of the input data, which can be useful for generalizing to new, unseen text data. This make advantages make it suit the task better.\n",
        "\n",
        "In conclusion the selected model classiffier i will go for is the **Support Vector Machine and Convolusion Neural Network**"
      ],
      "metadata": {
        "id": "iukLYeB6rl20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poV84q-XHyTs",
        "outputId": "d5f49af3-8435-4063-8ddb-0762878ad437"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# google drive path\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = os.path.join('./CE807/Assignment2/',str(student_id)) \n",
        "GOOGLE_DRIVE_PATH = os.path.join('gdrive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "print('List files: ', os.listdir(GOOGLE_DRIVE_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RbahR3gH_sE",
        "outputId": "4bbf665a-33df-427f-fff5-aabc16ef8276"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List files:  ['test.csv', 'valid.csv', 'train.csv', '.ipynb_checkpoints', 'train_25_sample.csv', 'train_50_sample.csv', 'train_75_sample.csv', 'cnn_model.pkl', 'cnn_predictions.csv', 'output.csv', 'cnn_model_frac_25.h5', 'cnn_model_frac_50.h5', 'output_cnn.csv', 'output_test_dtc.csv', 'svm_model.pkl', 'dtc_model.pkl', 'output_test_cnn.csv', 'cnn_model.h5', 'output_test_svm.csv', 'cnn_model_frac_60.h5', 'cnn_model_frac_75.h5', 'cnn_model_frac_85.h5', 'cnn_model_frac_100.h5', 'train_25pct.csv', 'train_75pct.csv', 'train_100pct.csv', 'train_50pct.csv', 'output_label_cnn_50.0.csv', 'output_label_cnn_100.0.csv', 'output_label_cnn_75.0.csv', 'output_label_cnn_25.0.csv', 'train_25pct_output_test_svm.csv', 'train_50pct_output_test_svm.csv', 'train_75pct_output_test_svm.csv', 'train_100pct_output_test_svm.csv', 'svm_model_0.6.pkl', 'svm_model_0.75.pkl', 'svm_model_0.85.pkl', 'svm_model_1.0.pkl', 'svm_predicted_labels.csv', 'cnn_predictions_label.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set path for train, validation and test dataset\n",
        "\n",
        "val_file = os.path.join(GOOGLE_DRIVE_PATH, 'valid.csv')\n",
        "print('Validation file: ', val_file)\n",
        "\n",
        "test_file = os.path.join(GOOGLE_DRIVE_PATH, 'test.csv')\n",
        "print('Test file: ', test_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbE8pL5XL4Lc",
        "outputId": "eab34a51-f511-40c8-a1e4-b42feff2e854"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation file:  gdrive/MyDrive/./CE807/Assignment2/2204923/valid.csv\n",
            "Test file:  gdrive/MyDrive/./CE807/Assignment2/2204923/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 directory"
      ],
      "metadata": {
        "id": "Jbb5s9sZWuAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_1_DIRECTORY = os.path.join(GOOGLE_DRIVE_PATH, 'svm_model.pkl', '1') # Model 1 directory\n",
        "print('Model 1 directory: ', MODEL_1_DIRECTORY)\n",
        "\n",
        "MODEL_1_25_DIRECTORY = os.path.join(MODEL_1_DIRECTORY,'25') # Model 1 trained using 25% of train data directory\n",
        "print('Model 1 directory with 25% data: ', MODEL_1_25_DIRECTORY)\n",
        "\n",
        "MODEL_1_50_DIRECTORY = os.path.join(MODEL_1_DIRECTORY,'50') # Model 1 trained using 50% of train data directory\n",
        "print('Model 1 directory with 50% data: ', MODEL_1_50_DIRECTORY)\n",
        "\n",
        "MODEL_1_75_DIRECTORY = os.path.join(MODEL_1_DIRECTORY,'75') # Model 1 trained using 75% of train data directory\n",
        "print('Model 1 directory with 75% data: ', MODEL_1_75_DIRECTORY)\n",
        "\n",
        "\n",
        "MODEL_1_100_DIRECTORY = os.path.join(MODEL_1_DIRECTORY,'100') # Model 1 trained using 100% of train data directory\n",
        "print('Model 1 directory with 100% data: ', MODEL_1_100_DIRECTORY)\n",
        "\n",
        "\n",
        "model_1_25_output_test_file = os.path.join(MODEL_1_25_DIRECTORY, 'train_25pct_output_test_svm.csv') # Output file using Model 1 trained using 25% of train data \n",
        "print('Output file name using model 1 using 25% of train data: ',model_1_25_output_test_file)\n",
        "\n",
        "model_1_50_output_test_file = os.path.join(MODEL_1_50_DIRECTORY, 'train_50pct_output_test_svm.csv') # Output file using Model 1 trained using 25% of train data \n",
        "print('Output file name using model 1 using 50% of train data: ',model_1_50_output_test_file)\n",
        "\n",
        "model_1_75_output_test_file = os.path.join(MODEL_1_75_DIRECTORY, 'train_75pct_output_test_svm.csv') # Output file using Model 1 trained using 25% of train data \n",
        "print('Output file name using model 1 using 25% of train data: ',model_1_75_output_test_file)\n",
        "\n",
        "model_1_100_output_test_file = os.path.join(MODEL_1_100_DIRECTORY, 'train_100pct_output_test_svm.csv') # Output file using Model 1 trained using 25% of train data \n",
        "print('Output file name using model 1 using 100% of train data: ',model_1_100_output_test_file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3egKulAhNNIe",
        "outputId": "da0fac0c-5b3e-49f2-dffb-6b872d806d16"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 directory:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1\n",
            "Model 1 directory with 25% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1/25\n",
            "Model 1 directory with 50% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1/50\n",
            "Model 1 directory with 75% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1/75\n",
            "Model 1 directory with 100% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1/100\n",
            "Output file name using model 1 using 25% of train data:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1/25/train_25pct_output_test_svm.csv\n",
            "Output file name using model 1 using 50% of train data:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1/50/train_50pct_output_test_svm.csv\n",
            "Output file name using model 1 using 25% of train data:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1/75/train_75pct_output_test_svm.csv\n",
            "Output file name using model 1 using 100% of train data:  gdrive/MyDrive/./CE807/Assignment2/2204923/svm_model.pkl/1/100/train_100pct_output_test_svm.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2 directory"
      ],
      "metadata": {
        "id": "O4xsdbavZ6lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_2_DIRECTORY = os.path.join(GOOGLE_DRIVE_PATH, 'cnn_model.h5', '1') # Model 2 directory\n",
        "print('Model 2 directory: ', MODEL_2_DIRECTORY)\n",
        "\n",
        "MODEL_2_25_DIRECTORY = os.path.join(MODEL_2_DIRECTORY,'25') # Model 2 trained using 25% of train data directory\n",
        "print('Model 2 directory with 25% data: ', MODEL_2_25_DIRECTORY)\n",
        "\n",
        "MODEL_2_50_DIRECTORY = os.path.join(MODEL_2_DIRECTORY,'50') # Model 2 trained using 50% of train data directory\n",
        "print('Model 2 directory with 50% data: ', MODEL_2_50_DIRECTORY)\n",
        "\n",
        "MODEL_2_75_DIRECTORY = os.path.join(MODEL_2_DIRECTORY,'75') # Model 2 trained using 75% of train data directory\n",
        "print('Model 2 directory with 75% data: ', MODEL_2_75_DIRECTORY)\n",
        "\n",
        "\n",
        "MODEL_2_100_DIRECTORY = os.path.join(MODEL_2_DIRECTORY,'100') # Model 2 trained using 100% of train data directory\n",
        "print('Model 2 directory with 100% data: ', MODEL_2_100_DIRECTORY)\n",
        "\n",
        "\n",
        "model_2_25_output_test_file = os.path.join(MODEL_2_25_DIRECTORY, 'output_label_cnn25.0.csv') # Output file using Model 2 trained using 25% of train data \n",
        "print('Output file name using model 2 using 25% of train data: ',model_2_25_output_test_file)\n",
        "\n",
        "model_2_50_output_test_file = os.path.join(MODEL_2_50_DIRECTORY, 'output_label_cnn50.0.csv') # Output file using Model 2 trained using 50% of train data \n",
        "print('Output file name using model 2 using 50% of train data: ',model_2_50_output_test_file)\n",
        "\n",
        "model_2_75_output_test_file = os.path.join(MODEL_2_75_DIRECTORY, 'output_label_cnn75.0.csv') # Output file using Model 2 trained using 25% of train data \n",
        "print('Output file name using model 2 using 25% of train data: ',model_2_75_output_test_file)\n",
        "\n",
        "model_2_100_output_test_file = os.path.join(MODEL_2_100_DIRECTORY, 'output_label_cnn100.0.csv') # Output file using Model 2 trained using 25% of train data \n",
        "print('Output file name using model 2 using 100% of train data: ',model_2_100_output_test_file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-D5F-9pW1iK",
        "outputId": "d8a24049-acbe-48e1-a29f-8535b30c6ef8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 directory:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1\n",
            "Model 2 directory with 25% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1/25\n",
            "Model 2 directory with 50% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1/50\n",
            "Model 2 directory with 75% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1/75\n",
            "Model 2 directory with 100% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1/100\n",
            "Output file name using model 2 using 25% of train data:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1/25/output_label_cnn25.0.csv\n",
            "Output file name using model 2 using 50% of train data:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1/50/output_label_cnn50.0.csv\n",
            "Output file name using model 2 using 25% of train data:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1/75/output_label_cnn75.0.csv\n",
            "Output file name using model 2 using 100% of train data:  gdrive/MyDrive/./CE807/Assignment2/2204923/cnn_model.h5/1/100/output_label_cnn100.0.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 2**\n",
        "**Method 1, training with support vector machine**"
      ],
      "metadata": {
        "id": "-oMkqmbYMHwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Define the function for loading the data\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv')\n",
        "    X = data['tweet'].values\n",
        "    y = data['label'].values\n",
        "    return X, y\n",
        "\n",
        "# Define the function for extracting handcrafted features from the text\n",
        "def extract_handcrafted_features(texts):\n",
        "    features = []\n",
        "    for text in texts:\n",
        "        # Extract handcrafted features such as character n-grams, punctuation marks, capitalization, etc.\n",
        "        # Append the features to the list\n",
        "        features.append([len(text), len(text.split()), len(text.splitlines())])\n",
        "    return np.array(features)\n",
        "\n",
        "# Load the training, validation, and test data\n",
        "X_train_full, y_train_full = load_data('train.csv')\n",
        "X_val, y_val = load_data('valid.csv')\n",
        "X_test, y_test = load_data('test.csv')\n",
        "\n",
        "# Split the training data into four subsets with different sizes (60%,  75%, 85% and 100%)\n",
        "train_sizes = [0.6, 0.75, 0.85, 1.0]\n",
        "for size in train_sizes:\n",
        "    # Select a random subset of the training data with the specified size\n",
        "    X_train, y_train = load_data('train.csv')\n",
        "    indices = np.random.choice(len(X_train), int(len(X_train) * size), replace=False)\n",
        "    X_train = X_train[indices]\n",
        "    y_train = y_train[indices]\n",
        "\n",
        "    # Represent the text using word n-grams\n",
        "    vectorizer = CountVectorizer(ngram_range=(1,3), stop_words='english')\n",
        "    X_train_ngrams = vectorizer.fit_transform(X_train)\n",
        "    X_val_ngrams = vectorizer.transform(X_val)\n",
        "\n",
        "    # Train the SVM model with word n-grams\n",
        "    svm_model = SVC()\n",
        "    svm_model.fit(X_train_ngrams, y_train)\n",
        "\n",
        "    # Save the model to a file\n",
        "    joblib.dump(svm_model, f'/content/gdrive/MyDrive/CE807/Assignment2/2204923/svm_model_{size}.pkl')\n",
        "\n",
        "    # Evaluate the SVM model on the validation set with word n-grams\n",
        "    y_pred_svm_ngrams = svm_model.predict(X_val_ngrams)\n",
        "    accuracy_svm_ngrams = svm_model.score(X_val_ngrams, y_val)\n",
        "\n",
        "    # Compute the evaluation metrics\n",
        "    print(f\"SVM with {size*100}% of training data:\")\n",
        "    print(\"F1 score:\", f1_score(y_val, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "    print(\"Precision:\", precision_score(y_val, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "    print(\"Recall:\", recall_score(y_val, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "    print(\"Macro F1 score:\", f1_score(y_val, y_pred_svm_ngrams, average='macro'))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_pred_svm_ngrams))\n",
        "    print(f\"Accuracy of SVM with {size*100}% of training data:\", accuracy_svm_ngrams)\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7n6ffuIIuXt",
        "outputId": "b31bc131-03a6-4d8b-edcc-5da97cc12307"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM with 60.0% of training data:\n",
            "F1 score: 0.3318494536624848\n",
            "Precision: 0.9647058823529412\n",
            "Recall: 0.20039100684261973\n",
            "Macro F1 score: 0.5820494982191717\n",
            "Confusion matrix:\n",
            " [[8191   30]\n",
            " [3272  820]]\n",
            "Accuracy of SVM with 60.0% of training data: 0.731828149110696\n",
            "\n",
            "SVM with 75.0% of training data:\n",
            "F1 score: 0.40015509887553313\n",
            "Precision: 0.9681050656660413\n",
            "Recall: 0.25219941348973607\n",
            "Macro F1 score: 0.6206138140771749\n",
            "Confusion matrix:\n",
            " [[8187   34]\n",
            " [3060 1032]]\n",
            "Accuracy of SVM with 75.0% of training data: 0.7487208641273451\n",
            "\n",
            "SVM with 85.0% of training data:\n",
            "F1 score: 0.46079344384429133\n",
            "Precision: 0.9686765857478465\n",
            "Recall: 0.302297165200391\n",
            "Macro F1 score: 0.6552292503533654\n",
            "Confusion matrix:\n",
            " [[8181   40]\n",
            " [2855 1237]]\n",
            "Accuracy of SVM with 85.0% of training data: 0.76488264435962\n",
            "\n",
            "SVM with 100.0% of training data:\n",
            "F1 score: 0.5002718868950515\n",
            "Precision: 0.968421052631579\n",
            "Recall: 0.33724340175953077\n",
            "Macro F1 score: 0.6779971606750101\n",
            "Confusion matrix:\n",
            " [[8176   45]\n",
            " [2712 1380]]\n",
            "Accuracy of SVM with 100.0% of training data: 0.7760903110533582\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The executed code consists of functions for training and evaluating a Support Vector Machine (SVM) model on a text classification task. The task involves classifying tweets as either offensive or non-offensive. The code uses the scikit-learn library for machine learning and pandas library for data manipulation.\n",
        "\n",
        "The load_data function reads in the training data from a CSV file and returns the tweet texts and their corresponding labels as NumPy arrays. The extract_handcrafted_features function extracts several handcrafted features from the text, such as character n-grams, punctuation marks, and capitalization, and returns them as a NumPy array.\n",
        "\n",
        "The training, validation, and test data are loaded using the load_data function. The training data is then split into four random subsets with different sizes using the train_sizes list. For each subset, a random sample subset of the training data with the specified size is selected. The text is represented using word n-grams using the CountVectorizer from scikit-learn. The SVM model is then trained on the training data with word n-grams using the SVM from scikit-learn. The trained model is saved to a file using the joblib library. The SVM model is evaluated on the validation set with word n-grams using several evaluation metrics, including F1 score, precision, recall, macro F1 score, and confusion matrix. Firstly, we take 60% of the training dataset which give accuracy of 0.73 and then increase the sample by 15% which make it 75% of the training dataset, give an accuracy of 0.75 and the with another increment of 15% gives an accuracy of 0.76 and then proceed by training the whole dataset which give an accuracy of 0.78 approximately.\n",
        "\n",
        "The code uses a standard machine learning pipeline to train and evaluate an SVM model on a text classification task. It also provides a simple way to experiment with different training set sizes and evaluate the impact on the model's performance. \n",
        "\n"
      ],
      "metadata": {
        "id": "TW8dZx87n11p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to ramdomly generate the sample size is shown in the code below. This allows a function to be built in order to get the performace metrics of each sample differently."
      ],
      "metadata": {
        "id": "IB4qXZny8a88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load the train.csv file into a pandas dataframe\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv')\n",
        "\n",
        "# take a random sample of 60% of the dataframe\n",
        "sample_60_df = df.sample(frac=0.6, random_state=42)\n",
        "\n",
        "# take a random sample of 75% of the dataframe\n",
        "sample_75_df = df.sample(frac=0.75, random_state=42)\n",
        "\n",
        "# take a random sample of 85% of the dataframe\n",
        "sample_85_df = df.sample(frac=0.85, random_state=42)\n",
        "\n",
        "\n",
        "# save the sample as a new csv files\n",
        "sample_60_df.to_csv('train_60_sample.csv', index=False)\n",
        "sample_75_df.to_csv('train_75_sample.csv', index=False)\n",
        "sample_85_df.to_csv('train_85_sample.csv', index=False)\n",
        "\n",
        "train_100_df = os.path.join(GOOGLE_DRIVE_PATH, 'train.csv') # This is 100% of data\n",
        "train_60_df = os.path.join(GOOGLE_DRIVE_PATH, 'train_60_sample.csv') #Let's assume that you have train 25% file is saved in train_25pct.csv. Note that this is a dummy file. You have to create your own file.\n",
        "train_75_df = os.path.join(GOOGLE_DRIVE_PATH, 'train_75_sample.csv') #Let's assume that you have train 50% file is saved in train_25pct.csv. Note that this is a dummy file. You have to create your own file.\n",
        "train_85_df = os.path.join(GOOGLE_DRIVE_PATH, 'train_85_sample.csv') #Let's assume that you have train 75% file is saved in train_25pct.csv. Note that this is a dummy file. You have to create your own file.\n",
        "\n",
        "\n",
        "print('Train 100% data: ', train_100_df)\n",
        "print('Train 60% data: ', train_60_df)\n",
        "print('Train 75% data: ', train_75_df)\n",
        "print('Train 85% data: ', train_85_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krYBJlvt8JWa",
        "outputId": "04cc652a-823c-4947-c838-a40cbb532aa9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 100% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/train.csv\n",
            "Train 60% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/train_60_sample.csv\n",
            "Train 75% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/train_75_sample.csv\n",
            "Train 85% data:  gdrive/MyDrive/./CE807/Assignment2/2204923/train_85_sample.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and test the model on test dataset"
      ],
      "metadata": {
        "id": "7_ySIlDuolgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_model(model_file_path, test_file_path, predicted_labels_file_path):\n",
        "    # Load the SVM model from a file\n",
        "    svm_model = joblib.load(model_file_path)\n",
        "\n",
        "    # Load the test data\n",
        "    X_test, y_test = load_data(test_file_path)\n",
        "\n",
        "    # Represent the text using word n-grams\n",
        "    vectorizer = CountVectorizer(ngram_range=(1,3), stop_words='english')\n",
        "    X_test_ngrams = vectorizer.fit_transform(X_test)\n",
        "\n",
        "    # Use the SVM model to predict the labels of the test data\n",
        "    y_pred_svm_ngrams = svm_model.predict(X_test_ngrams)\n",
        "\n",
        "    # Save the predicted labels to a file\n",
        "    with open(predicted_labels_file_path, 'w') as f:\n",
        "        f.write(' '.join(map(str, y_pred_svm_ngrams)))\n",
        "\n",
        "    # Compute the evaluation metrics\n",
        "    print(\"SVM test results:\")\n",
        "    print(\"F1 score:\", f1_score(y_test, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred_svm_ngrams, average='binary', pos_label='OFF'))\n",
        "    print(\"Macro F1 score:\", f1_score(y_test, y_pred_svm_ngrams, average='macro'))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_svm_ngrams))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm_ngrams))\n",
        "    \n",
        "# Call the function\n",
        "svm_model('/content/gdrive/MyDrive/CE807/Assignment2/2204923/svm_model.pkl', \n",
        "          '/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv', \n",
        "          '/content/gdrive/MyDrive/CE807/Assignment2/2204923/svm_predicted_labels.csv')\n"
      ],
      "metadata": {
        "id": "0lz8ILSRre1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e223d25-6419-4c0b-a61d-77a24c1fbaac"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM test results:\n",
            "F1 score: 0.9950992403822593\n",
            "Precision: 0.9977886977886978\n",
            "Recall: 0.9924242424242424\n",
            "Macro F1 score: 0.9963348485681948\n",
            "Confusion matrix:\n",
            " [[8212    9]\n",
            " [  31 4061]]\n",
            "Accuracy: 0.9967514009583367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code define Svm function that take the parameter of svm model path, test dataset and prediction label directory which give the prediction outcome label."
      ],
      "metadata": {
        "id": "BjPvGUn345BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the svm test dataset with the output label \n",
        "df_svm = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv')\n",
        "out_svm = pd.DataFrame( y_pred_svm_ngrams, columns=['Output_label'])\n",
        "df_svm['Output_label'] = out_svm\n",
        "print(df_svm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pzGokXD8rxT",
        "outputId": "5a2f9218-49c4-4b05-9f4c-ef280db8afb7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                                              tweet label  \\\n",
            "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   OFF   \n",
            "1    27014  #ConstitutionDay is revered by Conservatives, ...   NOT   \n",
            "2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...   NOT   \n",
            "3    13876  #Watching #Boomer getting the news that she is...   NOT   \n",
            "4    60133  #NoPasaran: Unity demo to oppose the far-right...   OFF   \n",
            "..     ...                                                ...   ...   \n",
            "855  73439  #DespicableDems lie again about rifles. Dem Di...   OFF   \n",
            "856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...   NOT   \n",
            "857  67018  3 people just unfollowed me for talking about ...   OFF   \n",
            "858  50665  #WednesdayWisdom Antifa calls the right fascis...   NOT   \n",
            "859  24583      #Kavanaugh typical #liberals , #Democrats URL   NOT   \n",
            "\n",
            "    Output_label  \n",
            "0            NOT  \n",
            "1            NOT  \n",
            "2            NOT  \n",
            "3            NOT  \n",
            "4            OFF  \n",
            "..           ...  \n",
            "855          OFF  \n",
            "856          NOT  \n",
            "857          NOT  \n",
            "858          OFF  \n",
            "859          NOT  \n",
            "\n",
            "[860 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_svm\n",
        "df_svm.to_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/output_test_svm.csv', index=False)\n",
        "df_svm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Uv0N4UOc-zRg",
        "outputId": "621b58f9-4a05-497a-f35a-332caf123ebb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              tweet label  \\\n",
              "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   OFF   \n",
              "1    27014  #ConstitutionDay is revered by Conservatives, ...   NOT   \n",
              "2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...   NOT   \n",
              "3    13876  #Watching #Boomer getting the news that she is...   NOT   \n",
              "4    60133  #NoPasaran: Unity demo to oppose the far-right...   OFF   \n",
              "..     ...                                                ...   ...   \n",
              "855  73439  #DespicableDems lie again about rifles. Dem Di...   OFF   \n",
              "856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...   NOT   \n",
              "857  67018  3 people just unfollowed me for talking about ...   OFF   \n",
              "858  50665  #WednesdayWisdom Antifa calls the right fascis...   NOT   \n",
              "859  24583      #Kavanaugh typical #liberals , #Democrats URL   NOT   \n",
              "\n",
              "    Output_label  \n",
              "0            NOT  \n",
              "1            NOT  \n",
              "2            NOT  \n",
              "3            NOT  \n",
              "4            OFF  \n",
              "..           ...  \n",
              "855          OFF  \n",
              "856          NOT  \n",
              "857          NOT  \n",
              "858          OFF  \n",
              "859          NOT  \n",
              "\n",
              "[860 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1da9ccd5-e32b-4c23-9332-71277a6bc278\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>Output_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15923</td>\n",
              "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27014</td>\n",
              "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30530</td>\n",
              "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13876</td>\n",
              "      <td>#Watching #Boomer getting the news that she is...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60133</td>\n",
              "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>73439</td>\n",
              "      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>25657</td>\n",
              "      <td>#MeetTheSpeakers 🙌 @USER will present in our e...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>67018</td>\n",
              "      <td>3 people just unfollowed me for talking about ...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>50665</td>\n",
              "      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>24583</td>\n",
              "      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>860 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1da9ccd5-e32b-4c23-9332-71277a6bc278')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1da9ccd5-e32b-4c23-9332-71277a6bc278 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1da9ccd5-e32b-4c23-9332-71277a6bc278');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 2, CNN model"
      ],
      "metadata": {
        "id": "85AC2pikcEPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv')\n",
        "test_data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv')\n",
        "valid_data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/valid.csv')\n",
        "\n",
        "# Shuffle the data\n",
        "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Tokenize the text and remove stop words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['tweet'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['tweet'])\n",
        "X_train = [[word for word in seq if word not in stop_words] for seq in X_train]\n",
        "X_test = tokenizer.texts_to_sequences(test_data['tweet'])\n",
        "X_test = [[word for word in seq if word not in stop_words] for seq in X_test]\n",
        "X_valid = tokenizer.texts_to_sequences(valid_data['tweet'])\n",
        "X_valid = [[word for word in seq if word not in stop_words] for seq in X_valid]\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "max_len = 100\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "X_valid = pad_sequences(X_valid, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Encode the labels\n",
        "encoder = LabelEncoder()\n",
        "train_data['label'] = encoder.fit_transform(train_data['label'])\n",
        "test_data['label'] = encoder.transform(test_data['label'])\n",
        "valid_data['label'] = encoder.transform(valid_data['label'])\n",
        "\n",
        "# Train the model\n",
        "history_list = []\n",
        "for i, frac in enumerate([0.60, 0.75, 0.85, 1.0]):\n",
        "    print(\"Training on\", frac*100, \"% of the data\")\n",
        "    # Select a fraction of the training data\n",
        "    train_frac = train_data.sample(frac=frac)\n",
        "    X_train_frac = tokenizer.texts_to_sequences(train_frac['tweet'])\n",
        "    X_train_frac = pad_sequences(X_train_frac, maxlen=max_len, padding='post', truncating='post')\n",
        "    y_train_frac = train_frac['label']\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_len))\n",
        "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_frac, y_train_frac, epochs=10, batch_size=64, validation_split=0.1, verbose=0)\n",
        "    history_list.append(history)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    # Evaluate the model on the validation set\n",
        "    y_pred_cnn = model.predict(X_valid)\n",
        "    y_pred_cnn = np.round(y_pred_cnn).flatten()\n",
        "    print(classification_report(valid_data['label'], y_pred_cnn))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(valid_data['label'], y_pred_cnn))\n",
        "    print('')\n",
        "    # Save the model\n",
        "    model.save(f'/content/gdrive/MyDrive/CE807/Assignment2/2204923/cnn_model_frac_{int(frac*100)}.h5')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('/content/gdrive/MyDrive/CE807/Assignment2/2204923/cnn_model_frac_100.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rFf7ec3tYLK",
        "outputId": "2fb334fc-5776-47e9-cf76-dcccb862e63f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 60.0 % of the data\n",
            "29/29 [==============================] - 0s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.82      0.79       619\n",
            "           1       0.58      0.50      0.54       308\n",
            "\n",
            "    accuracy                           0.72       927\n",
            "   macro avg       0.68      0.66      0.67       927\n",
            "weighted avg       0.71      0.72      0.71       927\n",
            "\n",
            "Confusion matrix:\n",
            " [[508 111]\n",
            " [153 155]]\n",
            "\n",
            "Training on 75.0 % of the data\n",
            "29/29 [==============================] - 0s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.78      0.78       619\n",
            "           1       0.56      0.56      0.56       308\n",
            "\n",
            "    accuracy                           0.71       927\n",
            "   macro avg       0.67      0.67      0.67       927\n",
            "weighted avg       0.71      0.71      0.71       927\n",
            "\n",
            "Confusion matrix:\n",
            " [[485 134]\n",
            " [135 173]]\n",
            "\n",
            "Training on 85.0 % of the data\n",
            "29/29 [==============================] - 1s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.82      0.80       619\n",
            "           1       0.60      0.54      0.57       308\n",
            "\n",
            "    accuracy                           0.73       927\n",
            "   macro avg       0.69      0.68      0.68       927\n",
            "weighted avg       0.72      0.73      0.72       927\n",
            "\n",
            "Confusion matrix:\n",
            " [[507 112]\n",
            " [141 167]]\n",
            "\n",
            "Training on 100.0 % of the data\n",
            "29/29 [==============================] - 0s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.81      0.80       619\n",
            "           1       0.60      0.55      0.57       308\n",
            "\n",
            "    accuracy                           0.73       927\n",
            "   macro avg       0.69      0.68      0.69       927\n",
            "weighted avg       0.72      0.73      0.72       927\n",
            "\n",
            "Confusion matrix:\n",
            " [[504 115]\n",
            " [138 170]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above implements a convolutional neural network (CNN) model to classify tweets into two categories, offensive and not offensive. The data is loaded from two CSV files, and then it is preprocessed by tokenizing the text and padding the sequences to a fixed length. The labels are encoded using the LabelEncoder 0 and 1 from Scikit-learn.\n",
        "\n",
        "I then trains the CNN model on different fractions of the training data and evaluates the model on the test set for each fraction. The CNN model consists of an embedding layer, followed by a one-dimensional convolutional layer, a max-pooling layer, a flattening layer, drop out layer which is used to nullifies the contribution of some neurons towards the next layer by dropping out the nodes in a neural network which take the parameter of 0.5, two dense layers with relu activation functions and a sigmoid activation function in the output layer. The model is compiled with binary cross-entropy loss and the Adam optimizer for faster computational time with fewer parameter tunning.\n",
        "\n",
        "After each training run, the  outputs a classification report and a confusion matrix for the model's performance on the test set is ouputed as follows- accuracy of approximately 0.70, 0.72, 0.72, and 0.72 in respective of 60%, 75%, 85% and 100% of randomly selected train dataset."
      ],
      "metadata": {
        "id": "ewaxKppSHf01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we load the cnn model and test it on test dataset. After then, we save the prediction output."
      ],
      "metadata": {
        "id": "LTpgtcwNbzs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, precision_score\n",
        "import os\n",
        "\n",
        "\n",
        "def cnn_model(model_path, test_data_path, output_dir):\n",
        "    # Load the model\n",
        "    loaded_model = tf.keras.models.load_model('/content/gdrive/MyDrive/CE807/Assignment2/2204923/cnn_model.h5')\n",
        "\n",
        "    # Load the test data\n",
        "    test_data = pd.read_csv('/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv')\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(test_data['tweet'])\n",
        "    X_test = tokenizer.texts_to_sequences(test_data['tweet'])\n",
        "    max_len = 100\n",
        "    X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    # Encode the labels\n",
        "    encoder = {'OFF': 1, 'NOT': 0}\n",
        "    test_data['label'] = test_data['label'].map(encoder)\n",
        "    \n",
        "    # Make predictions on the test data\n",
        "    y_pred = loaded_model.predict(X_test)\n",
        "    y_pred = np.round(y_pred).flatten()\n",
        "\n",
        "    # Save the predictions to a CSV file\n",
        "    output_path = os.path.join(output_dir, 'cnn_predictions_label.csv')\n",
        "    output_df = pd.DataFrame({'id': test_data['id'], 'label': y_pred})\n",
        "    output_df.to_csv(output_path, index=False)\n",
        "\n",
        "    # Calculate the performance metrics\n",
        "    accuracy = accuracy_score(test_data['label'], y_pred)\n",
        "    recall = recall_score(test_data['label'], y_pred)\n",
        "    precision = precision_score(test_data['label'], y_pred)\n",
        "    f1 = f1_score(test_data['label'], y_pred)\n",
        "    cmx = confusion_matrix(test_data['label'], y_pred)\n",
        "    # Print the performance metrics\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"Confusion matrix:\\n\", cmx )\n",
        "    print(output_df)\n",
        "    return accuracy, recall, precision, f1\n",
        "\n",
        "\n",
        "# call the function\n",
        "cnn_model('/content/gdrive/MyDrive/CE807/Assignment2/2204923/cnn_model.h5',\n",
        "           '/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv',\n",
        "           '/content/gdrive/MyDrive/CE807/Assignment2/2204923')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WghDA05O9pAs",
        "outputId": "ea66e761-1d44-42d6-d43f-e666007e3b3e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 19ms/step\n",
            "Accuracy: 0.586046511627907\n",
            "Recall: 0.3333333333333333\n",
            "Precision: 0.2898550724637681\n",
            "F1 Score: 0.31007751937984496\n",
            "Confusion matrix:\n",
            " [[424 196]\n",
            " [160  80]]\n",
            "        id  label\n",
            "0    15923    1.0\n",
            "1    27014    0.0\n",
            "2    30530    1.0\n",
            "3    13876    1.0\n",
            "4    60133    1.0\n",
            "..     ...    ...\n",
            "855  73439    1.0\n",
            "856  25657    0.0\n",
            "857  67018    1.0\n",
            "858  50665    0.0\n",
            "859  24583    0.0\n",
            "\n",
            "[860 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.586046511627907,\n",
              " 0.3333333333333333,\n",
              " 0.2898550724637681,\n",
              " 0.31007751937984496)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 3**\n",
        "Dividing the dataset into 4 subset data size of 25%, 50%, 75% and 100%"
      ],
      "metadata": {
        "id": "bOtnesRFFOLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# read the original train dataset\n",
        "traindfs = pd.read_csv(\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv\", index_col=0)\n",
        "\n",
        "# split the train dataset into four subsets of 25%, 50%, 75%, and 100%\n",
        "train_25pct, _ = train_test_split(traindf, train_size=0.25, random_state=42)\n",
        "train_50pct, _ = train_test_split(traindf, train_size=0.5, random_state=42)\n",
        "train_75pct, _ = train_test_split(traindf, train_size=0.75, random_state=42)\n",
        "train_100pct = traindfs\n",
        "\n",
        "# save each subset to a separate CSV file\n",
        "train_25pct.to_csv(\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_25pct.csv\")\n",
        "train_50pct.to_csv(\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_50pct.csv\")\n",
        "train_75pct.to_csv(\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_75pct.csv\")\n",
        "train_100pct.to_csv(\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_100pct.csv\")\n",
        "print(train_25pct)\n",
        "print(train_25pct.shape)\n",
        "print('')\n",
        "print(train_50pct)\n",
        "print(train_50pct.shape)\n",
        "print('')\n",
        "print(train_75pct)\n",
        "print(train_75pct.shape)\n",
        "print('')\n",
        "print(train_100pct)\n",
        "print(train_100pct.shape)\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syZjxTIv60cW",
        "outputId": "6c3291c8-e51e-4090-f0b0-aefbd44e1027"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   tweet label\n",
            "id                                                            \n",
            "11275  @USER as Libertarian all this shows me is how ...   OFF\n",
            "27420  @USER @USER How about really healing the count...   OFF\n",
            "48645  @USER @USER It crossed my mind that Sheriff Is...   OFF\n",
            "12264  @USER @USER @USER wow @USER are these the type...   NOT\n",
            "14708  90% of these conservatives\" really aren't. The...   NOT\n",
            "...                                                  ...   ...\n",
            "76038  @USER If Kerry clown is actually doing it and ...   OFF\n",
            "12668  @USER But when dealing with liberals all bets ...   NOT\n",
            "27540  @USER @USER What difference does it make if th...   OFF\n",
            "10329  @USER @USER @USER #Feinstein needs to go. Her ...   OFF\n",
            "74527  #Levi #Strauss Takes Stand On Gun Control - UR...   NOT\n",
            "\n",
            "[3078 rows x 2 columns]\n",
            "(3078, 2)\n",
            "\n",
            "                                                   tweet label\n",
            "id                                                            \n",
            "81683  @USER So you’re saying THIS official is suppos...   OFF\n",
            "71845  @USER All this tape proves is that @USER was a...   OFF\n",
            "89747  @USER @USER is anything but an independent thi...   NOT\n",
            "32701  @USER He’s going to end up having a massive he...   NOT\n",
            "20540  @USER Yeah and....what’s the point of this art...   OFF\n",
            "...                                                  ...   ...\n",
            "76038  @USER If Kerry clown is actually doing it and ...   OFF\n",
            "12668  @USER But when dealing with liberals all bets ...   NOT\n",
            "27540  @USER @USER What difference does it make if th...   OFF\n",
            "10329  @USER @USER @USER #Feinstein needs to go. Her ...   OFF\n",
            "74527  #Levi #Strauss Takes Stand On Gun Control - UR...   NOT\n",
            "\n",
            "[6156 rows x 2 columns]\n",
            "(6156, 2)\n",
            "\n",
            "                                                   tweet label\n",
            "id                                                            \n",
            "81817  @USER Privat just means between B XVI and the ...   NOT\n",
            "56475  @USER @USER Gun control at its finest. If that...   NOT\n",
            "63762                                  @USER Bullshit!!!   OFF\n",
            "76966                                @USER Good thinking   NOT\n",
            "42423  @USER @USER @USER @USER You are as nasty as he is   OFF\n",
            "...                                                  ...   ...\n",
            "76038  @USER If Kerry clown is actually doing it and ...   OFF\n",
            "12668  @USER But when dealing with liberals all bets ...   NOT\n",
            "27540  @USER @USER What difference does it make if th...   OFF\n",
            "10329  @USER @USER @USER #Feinstein needs to go. Her ...   OFF\n",
            "74527  #Levi #Strauss Takes Stand On Gun Control - UR...   NOT\n",
            "\n",
            "[9234 rows x 2 columns]\n",
            "(9234, 2)\n",
            "\n",
            "                                                   tweet label\n",
            "id                                                            \n",
            "42884  @USER I’m done with you as well. An INTENTIONA...   NOT\n",
            "92152  I now have over 6k followers.  Only 94k to go ...   NOT\n",
            "65475  @USER Tom was bought! He is more interested in...   NOT\n",
            "22144  @USER @USER Even her brother thinks she is a m...   OFF\n",
            "81048  @USER @USER @USER @USER @USER I can understand...   OFF\n",
            "...                                                  ...   ...\n",
            "92805  And Soros money in their pocket. #maga🇺🇸🇺🇸🇺🇸🇺🇸...   NOT\n",
            "35989  @USER ur a fucking dumbass fr. there’s no way ...   OFF\n",
            "30188  .@USER They both want you to believe in yourse...   NOT\n",
            "96815  @USER It's like a reading a leaflet from Antif...   OFF\n",
            "10460  @USER And they have some of the strictest gun ...   OFF\n",
            "\n",
            "[12313 rows x 2 columns]\n",
            "(12313, 2)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proportion and shape of train data size"
      ],
      "metadata": {
        "id": "Qlu6Kt1QtIRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_train_dataset(train_size):\n",
        "    # construct the path to the CSV file based on the train_size parameter\n",
        "    csv_path = f\"/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_{train_size}pct.csv\"\n",
        "    \n",
        "    # read the dataset\n",
        "    traindfsize = pd.read_csv(csv_path, index_col=0)\n",
        "\n",
        "    # count the number of offensive and non-offensive examples\n",
        "    offensive_count = (traindfsize[\"label\"] == \"OFF\").sum()\n",
        "    non_offensive_count = (traindfsize[\"label\"] == \"NOT\").sum()\n",
        "\n",
        "    # calculate the proportions\n",
        "    total_count = len(traindfsize)\n",
        "    offensive_proportion = (offensive_count / total_count)*100\n",
        "    non_offensive_proportion = (non_offensive_count / total_count)*100\n",
        "\n",
        "    print(traindfsize.head())\n",
        "    print(\"\")\n",
        "    print(f\"shape of {train_size}% train dataset:\")\n",
        "    print(traindfsize.shape)\n",
        "    print(\"\")\n",
        "    print(f\"proportion of each label for {train_size}%\")\n",
        "    print(f\"Proportion of offensive speech: {offensive_proportion:.2f}\")\n",
        "    print(f\"Proportion of non-offensive speech: {non_offensive_proportion:.2f}\")\n",
        "\n",
        "# analyze the 25% train dataset\n",
        "analyze_train_dataset(25)\n",
        "\n",
        "# analyze the 50% train dataset\n",
        "analyze_train_dataset(50)\n",
        "\n",
        "# analyze the 75% train dataset\n",
        "analyze_train_dataset(75)\n",
        "\n",
        "# analyze the 100% train dataset\n",
        "analyze_train_dataset(100)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-6K9La5rHK5",
        "outputId": "ffbaca2d-32ed-4426-cbd9-6bf9749ace53"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   tweet label\n",
            "id                                                            \n",
            "11275  @USER as Libertarian all this shows me is how ...   OFF\n",
            "27420  @USER @USER How about really healing the count...   OFF\n",
            "48645  @USER @USER It crossed my mind that Sheriff Is...   OFF\n",
            "12264  @USER @USER @USER wow @USER are these the type...   NOT\n",
            "14708  90% of these conservatives\" really aren't. The...   NOT\n",
            "\n",
            "shape of 25% train dataset:\n",
            "(3078, 2)\n",
            "\n",
            "proportion of each label for 25%\n",
            "Proportion of offensive speech: 32.55\n",
            "Proportion of non-offensive speech: 67.45\n",
            "                                                   tweet label\n",
            "id                                                            \n",
            "81683  @USER So you’re saying THIS official is suppos...   OFF\n",
            "71845  @USER All this tape proves is that @USER was a...   OFF\n",
            "89747  @USER @USER is anything but an independent thi...   NOT\n",
            "32701  @USER He’s going to end up having a massive he...   NOT\n",
            "20540  @USER Yeah and....what’s the point of this art...   OFF\n",
            "\n",
            "shape of 50% train dataset:\n",
            "(6156, 2)\n",
            "\n",
            "proportion of each label for 50%\n",
            "Proportion of offensive speech: 33.41\n",
            "Proportion of non-offensive speech: 66.59\n",
            "                                                   tweet label\n",
            "id                                                            \n",
            "81817  @USER Privat just means between B XVI and the ...   NOT\n",
            "56475  @USER @USER Gun control at its finest. If that...   NOT\n",
            "63762                                  @USER Bullshit!!!   OFF\n",
            "76966                                @USER Good thinking   NOT\n",
            "42423  @USER @USER @USER @USER You are as nasty as he is   OFF\n",
            "\n",
            "shape of 75% train dataset:\n",
            "(9234, 2)\n",
            "\n",
            "proportion of each label for 75%\n",
            "Proportion of offensive speech: 33.45\n",
            "Proportion of non-offensive speech: 66.55\n",
            "                                                   tweet label\n",
            "id                                                            \n",
            "42884  @USER I’m done with you as well. An INTENTIONA...   NOT\n",
            "92152  I now have over 6k followers.  Only 94k to go ...   NOT\n",
            "65475  @USER Tom was bought! He is more interested in...   NOT\n",
            "22144  @USER @USER Even her brother thinks she is a m...   OFF\n",
            "81048  @USER @USER @USER @USER @USER I can understand...   OFF\n",
            "\n",
            "shape of 100% train dataset:\n",
            "(12313, 2)\n",
            "\n",
            "proportion of each label for 100%\n",
            "Proportion of offensive speech: 33.23\n",
            "Proportion of non-offensive speech: 66.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing support vector machine classifier on different subset of 25%, 50%, 75% and 100% using support vector machine and save the output test data into gdrive**"
      ],
      "metadata": {
        "id": "TE-xE-q6kGDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "val_acc_scores = []\n",
        "test_acc_scores = []\n",
        "  \n",
        "def train_test_svm(data_path, train_files, val_data_path, test_data_path):\n",
        "    global test_acc_scores, val_acc_scores \n",
        "\n",
        "    # Load the data using pandas read_csv function\n",
        "    data = pd.read_csv(data_path)\n",
        "    val_data = pd.read_csv(val_data_path)\n",
        "    test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "    # Define lists to hold the performance results\n",
        "    train_acc_scores = []\n",
        "    val_acc_scores = []\n",
        "    test_acc_scores = []\n",
        "    train_precisions = []\n",
        "    val_precisions = []\n",
        "    test_precisions = []\n",
        "    train_recalls = []\n",
        "    val_recalls = []\n",
        "    test_recalls = []\n",
        "    train_f1_scores = []\n",
        "    val_f1_scores = []\n",
        "    test_f1_scores = []\n",
        "\n",
        "    # Define the vectorizer and classifier\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    svm = SVC(C=1, gamma=0.01, kernel='linear')\n",
        "\n",
        "    for train_file in train_files:\n",
        "        # Load the training set based on the file path\n",
        "        train_data = pd.read_csv(train_file)\n",
        "        x_train = train_data['tweet']\n",
        "        y_train = train_data['label']\n",
        "        x_train = vectorizer.fit_transform(x_train)\n",
        "\n",
        "        # Fit the model and predict on the training set\n",
        "        svm.fit(x_train, y_train)\n",
        "        y_train_pred = svm.predict(x_train)\n",
        "\n",
        "        # Evaluate on the training set\n",
        "        train_acc = accuracy_score(y_train, y_train_pred)\n",
        "        train_acc_scores.append(train_acc)\n",
        "        train_precision = precision_score(y_train, y_train_pred, average='macro')\n",
        "        train_precisions.append(train_precision)\n",
        "        train_recall = recall_score(y_train, y_train_pred, average='macro')\n",
        "        train_recalls.append(train_recall)\n",
        "        train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
        "        train_f1_scores.append(train_f1)\n",
        "\n",
        "        # Vectorize the validation and testing sets\n",
        "        x_val = vectorizer.transform(val_data['tweet'])\n",
        "        x_test = vectorizer.transform(test_data['tweet'])\n",
        "\n",
        "        # Evaluate on the validation set\n",
        "        y_val_pred = svm.predict(x_val)\n",
        "        val_acc = accuracy_score(val_data['label'], y_val_pred)\n",
        "        val_acc_scores.append(val_acc)\n",
        "        val_precision = precision_score(val_data['label'], y_val_pred, average='macro')\n",
        "        val_precisions.append(val_precision)\n",
        "        val_recall = recall_score(val_data['label'], y_val_pred, average='macro')\n",
        "        val_recalls.append(val_recall)\n",
        "        val_f1 = f1_score(val_data['label'], y_val_pred, average='macro')\n",
        "        val_f1_scores.append(val_f1)\n",
        "\n",
        "        # Evaluate on the testing set\n",
        "        y_test_pred = svm.predict(x_test)\n",
        "        test_acc = accuracy_score(test_data['label'], y_test_pred)\n",
        "        test_acc_scores.append(test_acc)\n",
        "        test_precision = precision_score(test_data['label'], y_test_pred, average='macro')\n",
        "        test_precisions.append(test_precision)\n",
        "        test_recall = recall_score(test_data['label'], y_test_pred, average='macro')\n",
        "        test_recalls.append(test_recall)\n",
        "        test_f1 = f1_score(test_data['label'], y_test_pred, average='macro')\n",
        "        test_f1_scores.append(test_f1)\n",
        "\n",
        "        # Write the test prediction output to file\n",
        "        test_data['predicted_label'] = y_test_pred\n",
        "        test_data.to_csv(os.path.splitext(train_file)[0] + '_output_test_svm.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "        # Print the performance metrics\n",
        "        print(f'Train Size: {os.path.basename(train_file)}')\n",
        "        print(f'Training Accuracy: {train_acc:.4f}')\n",
        "        print(f'Training Precision: {train_precision:.4f}')\n",
        "        print(f'Training Recall: {train_recall:.4f}')\n",
        "        print(f'Training F1 score: {train_f1:.4f}')\n",
        "        print('')\n",
        "        print('')\n",
        "        print(f'Train Size: {os.path.basename(train_file)}')\n",
        "        print(f'Validation Accuracy: {val_acc:.4f}')\n",
        "        print(f'Validation Precision: {val_precision:.4f}')\n",
        "        print(f'Validation Recall: {val_recall:.4f}')\n",
        "        print(f'Validation F1 score: {val_f1:.4f}')\n",
        "        print('')\n",
        "        print('')\n",
        "        print(f'Train Size: {os.path.basename(train_file)}')\n",
        "        print(f'Test Accuracy: {test_acc:.4f}')\n",
        "        print(f'Test Precision: {test_precision:.4f}')\n",
        "        print(f'Test Recall: {test_recall:.4f}')\n",
        "        print(f'Test F1 score: {test_f1:.4f}')\n",
        "        print('')\n",
        "# call the function\n",
        "data_path = '/content/gdrive/MyDrive/CE807/Assignment2/2204923/train.csv'\n",
        "#train_size_list = [0.25, 0.5, 0.75, 1]\n",
        "train_files = ['/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_25pct.csv',\n",
        "                   '/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_50pct.csv',\n",
        "                   '/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_75pct.csv',\n",
        "                   '/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_100pct.csv'\n",
        "]\n",
        "val_data_path = '/content/gdrive/MyDrive/CE807/Assignment2/2204923/valid.csv'\n",
        "test_data_path = '/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv'\n",
        "\n",
        "train_test_svm(data_path, train_files, val_data_path, test_data_path)\n",
        "print(test_acc_scores)\n",
        "print(val_acc_scores)\n",
        "              \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8qIYfYfOKV8",
        "outputId": "b5dc8054-13f5-473e-db07-07bcd1963878"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Size: train_25pct.csv\n",
            "Training Accuracy: 0.9168\n",
            "Training Precision: 0.9349\n",
            "Training Recall: 0.8779\n",
            "Training F1 score: 0.8992\n",
            "\n",
            "\n",
            "Train Size: train_25pct.csv\n",
            "Validation Accuracy: 0.7379\n",
            "Validation Precision: 0.7266\n",
            "Validation Recall: 0.6422\n",
            "Validation F1 score: 0.6502\n",
            "\n",
            "\n",
            "Train Size: train_25pct.csv\n",
            "Test Accuracy: 0.7849\n",
            "Test Precision: 0.7729\n",
            "Test Recall: 0.6478\n",
            "Test F1 score: 0.6661\n",
            "\n",
            "Train Size: train_50pct.csv\n",
            "Training Accuracy: 0.8944\n",
            "Training Precision: 0.9155\n",
            "Training Recall: 0.8499\n",
            "Training F1 score: 0.8723\n",
            "\n",
            "\n",
            "Train Size: train_50pct.csv\n",
            "Validation Accuracy: 0.7530\n",
            "Validation Precision: 0.7382\n",
            "Validation Recall: 0.6715\n",
            "Validation F1 score: 0.6836\n",
            "\n",
            "\n",
            "Train Size: train_50pct.csv\n",
            "Test Accuracy: 0.8140\n",
            "Test Precision: 0.8198\n",
            "Test Recall: 0.6935\n",
            "Test F1 score: 0.7201\n",
            "\n",
            "Train Size: train_75pct.csv\n",
            "Training Accuracy: 0.8882\n",
            "Training Precision: 0.9087\n",
            "Training Recall: 0.8423\n",
            "Training F1 score: 0.8646\n",
            "\n",
            "\n",
            "Train Size: train_75pct.csv\n",
            "Validation Accuracy: 0.7638\n",
            "Validation Precision: 0.7499\n",
            "Validation Recall: 0.6885\n",
            "Validation F1 score: 0.7020\n",
            "\n",
            "\n",
            "Train Size: train_75pct.csv\n",
            "Test Accuracy: 0.8256\n",
            "Test Precision: 0.8411\n",
            "Test Recall: 0.7092\n",
            "Test F1 score: 0.7386\n",
            "\n",
            "Train Size: train_100pct.csv\n",
            "Training Accuracy: 0.8812\n",
            "Training Precision: 0.8970\n",
            "Training Recall: 0.8347\n",
            "Training F1 score: 0.8559\n",
            "\n",
            "\n",
            "Train Size: train_100pct.csv\n",
            "Validation Accuracy: 0.7648\n",
            "Validation Precision: 0.7512\n",
            "Validation Recall: 0.6901\n",
            "Validation F1 score: 0.7037\n",
            "\n",
            "\n",
            "Train Size: train_100pct.csv\n",
            "Test Accuracy: 0.8256\n",
            "Test Precision: 0.8277\n",
            "Test Recall: 0.7169\n",
            "Test F1 score: 0.7447\n",
            "\n",
            "[0.7848837209302325, 0.813953488372093, 0.8255813953488372, 0.8255813953488372]\n",
            "[0.7378640776699029, 0.7529665587918015, 0.7637540453074434, 0.7648327939590076]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above is implementing a Support Vector Machine (SVM) model for a text classification task. The data is loaded using Pandas read_csv function, and the model is trained using the TF-IDF vectorizer and linear kernel SVM classifier (A linear kernel computes the dot product between the input vectors, which measures how much they overlap in the feature space.). The performance of the model is evaluated on training, validation, and testing sets using several evaluation metrics such as accuracy, precision, recall, and F1 score.\n",
        "\n",
        "The train_test_svm function takes four input arguments: data_path, train_files, val_data_path, and test_data_path. The data_path variable represents the path of the main training data file, train_files is a list of paths of different training set files of datafile, 25%, 50%, 75% and 100% with varying sizes, val_data_path represents the path of the validation data file, and test_data_path represents the path of the test data file.\n",
        "\n",
        "The function iterates through each train_file in train_files, loads the data, fits the model on the training set, and evaluates the performance of the model on the training, validation, and testing sets. The evaluation metrics are stored in separate lists, and the results are printed to the console.\n",
        "\n",
        "In conclusion, we see that the more the size of train dataset, the more the test set accuarcy which ranges from 0.78 to 0.83\n",
        "\n"
      ],
      "metadata": {
        "id": "RArvaDTIc9kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**plot the gragh to show the behaviour of SVC  performance metric again data size to show the behaviour of test dataset and validation data set**"
      ],
      "metadata": {
        "id": "xbLbQhzNk8C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_acc_scores)\n",
        "print(val_acc_scores)\n",
        "\n",
        "# Plot the results\n",
        "from matplotlib import pyplot as plt\n",
        "subset_sizes = [0.25, 0.5, 0.75, 1.0]\n",
        "\n",
        "plt.plot(subset_sizes, val_acc_scores, label='Validation Accuracy')\n",
        "plt.plot(subset_sizes, test_acc_scores, label='Test Accuracy')\n",
        "plt.xlabel('Data Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Data Size')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "V7GOi7fRvyIi",
        "outputId": "c27d9fed-e5cb-45f2-c098-77188afd9f4b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7848837209302325, 0.813953488372093, 0.8255813953488372, 0.8255813953488372]\n",
            "[0.7378640776699029, 0.7529665587918015, 0.7637540453074434, 0.7648327939590076]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph above demonstrate the relationship of the data size of the training dataset and the accuracy of the test dataset. This indicate that as the data size of the train dataset increases, the better the model fit the train dataset which lead to better accuracy of the test and validation of the data set."
      ],
      "metadata": {
        "id": "-NTAFXrlkiRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing the accuracy of 25%, 50%, 75% and 100% of training data using CNN**"
      ],
      "metadata": {
        "id": "q7G_FQqnPTbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def train_test_cnn(train_files, val_data_path, test_data_path, model_dir):\n",
        "    # Load the data\n",
        "    train_data_25 = pd.read_csv(train_files[0])\n",
        "    train_data_50 = pd.read_csv(train_files[1])\n",
        "    train_data_75 = pd.read_csv(train_files[2])\n",
        "    train_data_100 = pd.read_csv(train_files[3])\n",
        "    val_data = pd.read_csv(val_data_path)\n",
        "    test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(train_data_100['tweet'])\n",
        "    X_train_25 = tokenizer.texts_to_sequences(train_data_25['tweet'])\n",
        "    X_train_50 = tokenizer.texts_to_sequences(train_data_50['tweet'])\n",
        "    X_train_75 = tokenizer.texts_to_sequences(train_data_75['tweet'])\n",
        "    X_train_100 = tokenizer.texts_to_sequences(train_data_100['tweet'])\n",
        "    X_val = tokenizer.texts_to_sequences(val_data['tweet'])\n",
        "    X_test = tokenizer.texts_to_sequences(test_data['tweet'])\n",
        "    \n",
        "    # Remove stop words from the text sequences\n",
        "    X_train_25 = [[word for word in seq if word not in stop_words] for seq in X_train_25]\n",
        "    X_train_50 = [[word for word in seq if word not in stop_words] for seq in X_train_50]\n",
        "    X_train_75 = [[word for word in seq if word not in stop_words] for seq in X_train_75]\n",
        "    X_train_100 = [[word for word in seq if word not in stop_words] for seq in X_train_100]\n",
        "    X_val = [[word for word in seq if word not in stop_words] for seq in X_val]\n",
        "    X_test = [[word for word in seq if word not in stop_words] for seq in X_test]\n",
        "\n",
        "\n",
        "    # Pad the sequences to have the same length\n",
        "    max_len = 100\n",
        "    X_train_25 = pad_sequences(X_train_25, maxlen=max_len, padding='post', truncating='post')\n",
        "    X_train_50 = pad_sequences(X_train_50, maxlen=max_len, padding='post', truncating='post')\n",
        "    X_train_75 = pad_sequences(X_train_75, maxlen=max_len, padding='post', truncating='post')\n",
        "    X_train_100 = pad_sequences(X_train_100, maxlen=max_len, padding='post', truncating='post')\n",
        "    X_val = pad_sequences(X_val, maxlen=max_len, padding='post', truncating='post')\n",
        "    X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    # Encode the labels\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    encoder = LabelEncoder()\n",
        "    train_data_25['label'] = encoder.fit_transform(train_data_25['label'])\n",
        "    train_data_50['label'] = encoder.fit_transform(train_data_50['label'])\n",
        "    train_data_75['label'] = encoder.fit_transform(train_data_75['label'])\n",
        "    train_data_100['label'] = encoder.fit_transform(train_data_100['label'])\n",
        "    val_data['label'] = encoder.transform(val_data['label'])\n",
        "    test_data['label'] = encoder.transform(test_data['label'])\n",
        "\n",
        "    # Train the model on each subset\n",
        "    predictions_list = []\n",
        "    history_list = []\n",
        "    subsets = [(0.25, X_train_25, train_data_25['label']), \n",
        "               (0.5, X_train_50, train_data_50['label']), \n",
        "               (0.75, X_train_75, train_data_75['label']), \n",
        "               (1.0, X_train_100, train_data_100['label'])]\n",
        "    \n",
        "    for frac, X_train_frac, y_train_frac in subsets:\n",
        "        print(\"Training on\", frac*100, \"% of the data\")\n",
        "\n",
        "        # Define the CNN model\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_len))\n",
        "        model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=5))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(X_train_frac, y_train_frac, epochs=10, batch_size=32, validation_data=(X_val, val_data['label']))\n",
        "\n",
        "        # Save the model\n",
        "        #model.save(os.path.join(model_dir, f\"model_{frac}.h5\"))\n",
        "\n",
        "        # Add the history to the list\n",
        "        history_list.append(history)\n",
        "        # Return the histories and test scores\n",
        "        #return history_list, test_scores\n",
        "\n",
        "        # Save the predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "        predictions_list.append(y_pred)\n",
        "\n",
        "        # Save the predictions\n",
        "        for i, y_pred in enumerate(predictions_list):\n",
        "            frac = subsets[i][0]\n",
        "            pred_classes = encoder.inverse_transform((y_pred > 0.5).astype(int).ravel())\n",
        "            output_path = os.path.join('/content/gdrive/MyDrive/CE807/Assignment2/2204923', f\"output_label_cnn_{frac*100}.csv\")\n",
        "            test_data['pred_classes'] = pred_classes\n",
        "            test_data.to_csv(output_path, index=False)\n",
        "\n",
        "\n",
        "        # Evaluate the models on the test set\n",
        "        test_scores = []\n",
        "        val_scores  = []\n",
        "        for frac, X_train_frac, y_train_frac in subsets:\n",
        "            from tensorflow.keras.models import load_model\n",
        "            #model = load_model(os.path.join(model_dir, f\"model_{frac}.h5\"))\n",
        "            test_loss, test_acc = model.evaluate(X_test, test_data['label'], verbose=0)\n",
        "            test_scores.append((frac, test_loss, test_acc))\n",
        "            val_loss, val_acc = model.evaluate(X_val, val_data['label'], verbose=0)\n",
        "            val_scores.append((frac, val_loss, val_acc))\n",
        "        print(f\"Test set results for  the training data:\")\n",
        "        print(f\"  Loss: {test_loss:.4f}\")\n",
        "        print(f\"  Accuracy: {test_acc:.4f}\")\n",
        "        print(f\"Validation set results for  the training data:\")\n",
        "        print(f\"  Loss: {val_loss:.4f}\")\n",
        "        print(f\"  Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "# call the function\n",
        "train_files = ['/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_25pct.csv',\n",
        "                   '/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_50pct.csv',\n",
        "                   '/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_75pct.csv',\n",
        "                   '/content/gdrive/MyDrive/CE807/Assignment2/2204923/train_100pct.csv'\n",
        "]\n",
        "val_data_path = '/content/gdrive/MyDrive/CE807/Assignment2/2204923/valid.csv'\n",
        "test_data_path = '/content/gdrive/MyDrive/CE807/Assignment2/2204923/test.csv'\n",
        "model_dir = '/content/gdrive/MyDrive/CE807/Assignment2/2204923/cnn_model.h5'\n",
        "train_test_cnn(train_files, val_data_path, test_data_path, model_dir)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx7exzPSCmbh",
        "outputId": "556b596e-92c2-4a3e-9657-feb454affb58"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 25.0 % of the data\n",
            "Epoch 1/10\n",
            "97/97 [==============================] - 9s 79ms/step - loss: 0.6302 - accuracy: 0.6735 - val_loss: 0.6290 - val_accuracy: 0.6677\n",
            "Epoch 2/10\n",
            "97/97 [==============================] - 7s 68ms/step - loss: 0.5564 - accuracy: 0.7092 - val_loss: 0.5840 - val_accuracy: 0.6969\n",
            "Epoch 3/10\n",
            "97/97 [==============================] - 6s 64ms/step - loss: 0.2747 - accuracy: 0.9019 - val_loss: 0.6514 - val_accuracy: 0.7044\n",
            "Epoch 4/10\n",
            "97/97 [==============================] - 8s 82ms/step - loss: 0.0944 - accuracy: 0.9717 - val_loss: 0.7728 - val_accuracy: 0.7109\n",
            "Epoch 5/10\n",
            "97/97 [==============================] - 6s 60ms/step - loss: 0.0406 - accuracy: 0.9919 - val_loss: 0.9173 - val_accuracy: 0.7195\n",
            "Epoch 6/10\n",
            "97/97 [==============================] - 8s 87ms/step - loss: 0.0218 - accuracy: 0.9948 - val_loss: 0.9647 - val_accuracy: 0.7066\n",
            "Epoch 7/10\n",
            "97/97 [==============================] - 6s 59ms/step - loss: 0.0130 - accuracy: 0.9981 - val_loss: 1.0404 - val_accuracy: 0.7044\n",
            "Epoch 8/10\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 1.1305 - val_accuracy: 0.7120\n",
            "Epoch 9/10\n",
            "97/97 [==============================] - 7s 70ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 1.1648 - val_accuracy: 0.7109\n",
            "Epoch 10/10\n",
            "97/97 [==============================] - 6s 60ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 1.1937 - val_accuracy: 0.7033\n",
            "27/27 [==============================] - 1s 19ms/step\n",
            "Test set results for  the training data:\n",
            "  Loss: 1.0404\n",
            "  Accuracy: 0.7302\n",
            "Validation set results for  the training data:\n",
            "  Loss: 1.1937\n",
            "  Accuracy: 0.7033\n",
            "Training on 50.0 % of the data\n",
            "Epoch 1/10\n",
            "193/193 [==============================] - 14s 69ms/step - loss: 0.6301 - accuracy: 0.6668 - val_loss: 0.5956 - val_accuracy: 0.6861\n",
            "Epoch 2/10\n",
            "193/193 [==============================] - 12s 64ms/step - loss: 0.4471 - accuracy: 0.7953 - val_loss: 0.5353 - val_accuracy: 0.7519\n",
            "Epoch 3/10\n",
            "193/193 [==============================] - 13s 70ms/step - loss: 0.1946 - accuracy: 0.9287 - val_loss: 0.6861 - val_accuracy: 0.7174\n",
            "Epoch 4/10\n",
            "193/193 [==============================] - 14s 70ms/step - loss: 0.0784 - accuracy: 0.9764 - val_loss: 0.8094 - val_accuracy: 0.7195\n",
            "Epoch 5/10\n",
            "193/193 [==============================] - 14s 71ms/step - loss: 0.0345 - accuracy: 0.9922 - val_loss: 0.9592 - val_accuracy: 0.7325\n",
            "Epoch 6/10\n",
            "193/193 [==============================] - 14s 72ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 1.0740 - val_accuracy: 0.7238\n",
            "Epoch 7/10\n",
            "193/193 [==============================] - 12s 63ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 1.1623 - val_accuracy: 0.7249\n",
            "Epoch 8/10\n",
            "193/193 [==============================] - 13s 66ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 1.2231 - val_accuracy: 0.7217\n",
            "Epoch 9/10\n",
            "193/193 [==============================] - 14s 71ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 1.2925 - val_accuracy: 0.7271\n",
            "Epoch 10/10\n",
            "193/193 [==============================] - 14s 72ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 1.3272 - val_accuracy: 0.7184\n",
            "27/27 [==============================] - 1s 18ms/step\n",
            "Test set results for  the training data:\n",
            "  Loss: 1.1923\n",
            "  Accuracy: 0.7360\n",
            "Validation set results for  the training data:\n",
            "  Loss: 1.3272\n",
            "  Accuracy: 0.7184\n",
            "Training on 75.0 % of the data\n",
            "Epoch 1/10\n",
            "289/289 [==============================] - 20s 67ms/step - loss: 0.6029 - accuracy: 0.6861 - val_loss: 0.5260 - val_accuracy: 0.7605\n",
            "Epoch 2/10\n",
            "289/289 [==============================] - 19s 67ms/step - loss: 0.3965 - accuracy: 0.8255 - val_loss: 0.5525 - val_accuracy: 0.7497\n",
            "Epoch 3/10\n",
            "289/289 [==============================] - 21s 72ms/step - loss: 0.1828 - accuracy: 0.9333 - val_loss: 0.7109 - val_accuracy: 0.7314\n",
            "Epoch 4/10\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.0774 - accuracy: 0.9771 - val_loss: 0.8472 - val_accuracy: 0.7271\n",
            "Epoch 5/10\n",
            "289/289 [==============================] - 19s 66ms/step - loss: 0.0370 - accuracy: 0.9907 - val_loss: 0.9911 - val_accuracy: 0.7238\n",
            "Epoch 6/10\n",
            "289/289 [==============================] - 19s 67ms/step - loss: 0.0237 - accuracy: 0.9943 - val_loss: 1.0831 - val_accuracy: 0.7206\n",
            "Epoch 7/10\n",
            "289/289 [==============================] - 19s 67ms/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 1.1432 - val_accuracy: 0.7238\n",
            "Epoch 8/10\n",
            "289/289 [==============================] - 21s 71ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 1.1792 - val_accuracy: 0.7314\n",
            "Epoch 9/10\n",
            "289/289 [==============================] - 20s 71ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 1.1958 - val_accuracy: 0.7282\n",
            "Epoch 10/10\n",
            "289/289 [==============================] - 19s 67ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 1.2400 - val_accuracy: 0.7282\n",
            "27/27 [==============================] - 0s 12ms/step\n",
            "Test set results for  the training data:\n",
            "  Loss: 1.1106\n",
            "  Accuracy: 0.7523\n",
            "Validation set results for  the training data:\n",
            "  Loss: 1.2400\n",
            "  Accuracy: 0.7282\n",
            "Training on 100.0 % of the data\n",
            "Epoch 1/10\n",
            "385/385 [==============================] - 28s 72ms/step - loss: 0.5800 - accuracy: 0.7083 - val_loss: 0.5108 - val_accuracy: 0.7627\n",
            "Epoch 2/10\n",
            "385/385 [==============================] - 26s 67ms/step - loss: 0.3798 - accuracy: 0.8367 - val_loss: 0.5351 - val_accuracy: 0.7519\n",
            "Epoch 3/10\n",
            "385/385 [==============================] - 26s 68ms/step - loss: 0.1888 - accuracy: 0.9289 - val_loss: 0.7379 - val_accuracy: 0.7368\n",
            "Epoch 4/10\n",
            "385/385 [==============================] - 28s 72ms/step - loss: 0.0828 - accuracy: 0.9743 - val_loss: 0.8948 - val_accuracy: 0.7098\n",
            "Epoch 5/10\n",
            "385/385 [==============================] - 25s 64ms/step - loss: 0.0385 - accuracy: 0.9899 - val_loss: 1.0783 - val_accuracy: 0.7141\n",
            "Epoch 6/10\n",
            "385/385 [==============================] - 27s 70ms/step - loss: 0.0246 - accuracy: 0.9946 - val_loss: 1.1500 - val_accuracy: 0.7087\n",
            "Epoch 7/10\n",
            "385/385 [==============================] - 25s 66ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 1.2281 - val_accuracy: 0.7120\n",
            "Epoch 8/10\n",
            "385/385 [==============================] - 27s 69ms/step - loss: 0.0149 - accuracy: 0.9965 - val_loss: 1.2989 - val_accuracy: 0.7174\n",
            "Epoch 9/10\n",
            "385/385 [==============================] - 27s 70ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.4202 - val_accuracy: 0.7077\n",
            "Epoch 10/10\n",
            "385/385 [==============================] - 37s 96ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 1.3909 - val_accuracy: 0.7152\n",
            "27/27 [==============================] - 0s 10ms/step\n",
            "Test set results for  the training data:\n",
            "  Loss: 1.0897\n",
            "  Accuracy: 0.7581\n",
            "Validation set results for  the training data:\n",
            "  Loss: 1.3909\n",
            "  Accuracy: 0.7152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above is defining a function train_test_cnn that trains and tests a Convolutional Neural Network (CNN) model on different subsets of a given dataset. The subsets are determined by the percentage of data used for training, and the function trains a separate model for each subset. The function takes the file paths of the training, validation, and test datasets, and the path of a directory to save the trained models.\n",
        "\n",
        "in the function, i first loads the datasets using Pandas, and tokenizes the text using the Keras Tokenizer class. The text is padded to have the same length using the pad_sequences function. The labels are encoded using the LabelEncoder class from Scikit-learn.\n",
        "\n",
        "Next, i define a CNN model using the Keras Sequential class, with an embedding layer, a 1 dimension convolutional layer, a max-pooling layer, a flatten layer, and a dense layer. The model is compiled with the Adam optimizer for faster computation time and small parameter tunning and binary cross-entropy loss, and trained on each subset of the training data for 10 epochs (10 iteration of all training data in one cycle for training the neural network model). The training progress is saved in a list of histories.\n",
        "\n",
        "The function then evaluates the trained models on the test set and saves the predictions for each model in a separate file. The test accuracy result for 25% of the data is 0.75, for 50% is 0.74, for 75% is 0.76  and 100% is 0.77 approximately. The test result tells that irrespective of the data size, the model still fit well but a large dataset is preferable to obatin optimum result."
      ],
      "metadata": {
        "id": "nI82DJnKaGT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**plot the graph for performance measure for the CNN model against each subset size of the validation and test dataset**"
      ],
      "metadata": {
        "id": "hl0E3n9FKVay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test and validation score are presented in the list below\n",
        "testscores = [0.7303, 0.7360, 0.7523, 0.7581]\n",
        "valscores = [0.7033, 0.7184, 0.7282, 0.7152]\n",
        "\n",
        "print(testscores)\n",
        "print(valscores)\n",
        "\n",
        "# Plot the results\n",
        "from matplotlib import pyplot as plt\n",
        "subset_sizes = [0.25, 0.5, 0.75, 1.0]\n",
        "\n",
        "plt.plot(subset_sizes, valscores, label='Validation Accuracy')\n",
        "plt.plot(subset_sizes, testscores, label='Test Accuracy')\n",
        "plt.xlabel('Data Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Data Size')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "JR_Vm6_ksMWD",
        "outputId": "c02dca01-4540-4dc6-bf84-c7b001c4231c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7303, 0.736, 0.7523, 0.7581]\n",
            "[0.7033, 0.7184, 0.7282, 0.7152]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CNN plot of test and validation accuracy show that as the train data size increases, the test accuracy and validation dataset increases as the train dataset become larger, This shows that the larger the data size, the better the accuracy."
      ],
      "metadata": {
        "id": "JNJ3bEDJfQrz"
      }
    }
  ]
}